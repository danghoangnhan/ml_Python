{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from model.CNN.VGGNet import VGG_19\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.python.keras.callbacks import LearningRateScheduler\n",
    "from model.adaptiveLearning import step_decay\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import datasets,  losses, optimizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=10,\n",
    "                         width_shift_range=0.1,\n",
    "                         height_shift_range=0.1,\n",
    "                         shear_range=0.2,\n",
    "                         zoom_range=0.2,\n",
    "                         horizontal_flip=True,\n",
    "                         fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-23 23:25:10.956956: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-23 23:25:11.477919: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43662 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:17:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training\n",
    "epochs = 500\n",
    "batch_size = 512\n",
    "# Compile the model with a specific learning rate\n",
    "learning_rate = 0.001  # Set your desired learning rate here\n",
    "optimizer = optimizers.SGD(learning_rate=learning_rate, momentum=0.9)  # You can add momentum if desired\n",
    "\n",
    "num_classes = 10\n",
    "vgg19_model = VGG_19(width=32,height=32,depth=3,classes=num_classes)\n",
    "callbacks = [LearningRateScheduler(step_decay)]\n",
    "# Compile the model\n",
    "vgg19_model.compile(optimizer=optimizer,\n",
    "                    loss=losses.CategoricalCrossentropy(from_logits=True),\n",
    "                    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n",
      "2023-07-23 23:25:13.132077: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8903\n",
      "2023-07-23 23:25:14.488889: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 22s 196ms/step - loss: 2.3027 - accuracy: 0.0957 - val_loss: 2.3026 - val_accuracy: 0.1000 - lr: 0.0100\n",
      "Epoch 2/500\n",
      "98/98 [==============================] - 18s 183ms/step - loss: 2.3027 - accuracy: 0.0997 - val_loss: 2.3026 - val_accuracy: 0.1000 - lr: 0.0100\n",
      "Epoch 3/500\n",
      "98/98 [==============================] - 18s 183ms/step - loss: 2.3026 - accuracy: 0.0996 - val_loss: 2.3025 - val_accuracy: 0.1105 - lr: 0.0100\n",
      "Epoch 4/500\n",
      "98/98 [==============================] - 18s 183ms/step - loss: 2.3026 - accuracy: 0.0987 - val_loss: 2.3025 - val_accuracy: 0.1000 - lr: 0.0100\n",
      "Epoch 5/500\n",
      "98/98 [==============================] - 18s 180ms/step - loss: 2.3025 - accuracy: 0.1008 - val_loss: 2.3025 - val_accuracy: 0.1000 - lr: 0.0025\n",
      "Epoch 6/500\n",
      "98/98 [==============================] - 18s 183ms/step - loss: 2.3025 - accuracy: 0.1117 - val_loss: 2.3025 - val_accuracy: 0.1213 - lr: 0.0025\n",
      "Epoch 7/500\n",
      "98/98 [==============================] - 18s 184ms/step - loss: 2.3025 - accuracy: 0.1013 - val_loss: 2.3024 - val_accuracy: 0.1294 - lr: 0.0025\n",
      "Epoch 8/500\n",
      "98/98 [==============================] - 18s 182ms/step - loss: 2.3025 - accuracy: 0.1161 - val_loss: 2.3024 - val_accuracy: 0.1700 - lr: 0.0025\n",
      "Epoch 9/500\n",
      "98/98 [==============================] - 18s 180ms/step - loss: 2.3024 - accuracy: 0.1037 - val_loss: 2.3024 - val_accuracy: 0.1000 - lr: 0.0025\n",
      "Epoch 10/500\n",
      "98/98 [==============================] - 18s 181ms/step - loss: 2.3024 - accuracy: 0.1174 - val_loss: 2.3024 - val_accuracy: 0.1049 - lr: 6.2500e-04\n",
      "Epoch 11/500\n",
      "98/98 [==============================] - 18s 182ms/step - loss: 2.3024 - accuracy: 0.1137 - val_loss: 2.3024 - val_accuracy: 0.1482 - lr: 6.2500e-04\n",
      "Epoch 12/500\n",
      "98/98 [==============================] - 18s 181ms/step - loss: 2.3024 - accuracy: 0.1476 - val_loss: 2.3024 - val_accuracy: 0.1589 - lr: 6.2500e-04\n",
      "Epoch 13/500\n",
      "98/98 [==============================] - 18s 184ms/step - loss: 2.3024 - accuracy: 0.1227 - val_loss: 2.3024 - val_accuracy: 0.1596 - lr: 6.2500e-04\n",
      "Epoch 14/500\n",
      "98/98 [==============================] - 18s 181ms/step - loss: 2.3024 - accuracy: 0.1274 - val_loss: 2.3024 - val_accuracy: 0.1414 - lr: 6.2500e-04\n",
      "Epoch 15/500\n",
      "98/98 [==============================] - 18s 180ms/step - loss: 2.3024 - accuracy: 0.1577 - val_loss: 2.3024 - val_accuracy: 0.1612 - lr: 1.5625e-04\n",
      "Epoch 16/500\n",
      "98/98 [==============================] - 18s 179ms/step - loss: 2.3024 - accuracy: 0.1589 - val_loss: 2.3024 - val_accuracy: 0.1590 - lr: 1.5625e-04\n",
      "Epoch 17/500\n",
      "98/98 [==============================] - 18s 181ms/step - loss: 2.3024 - accuracy: 0.1627 - val_loss: 2.3024 - val_accuracy: 0.1583 - lr: 1.5625e-04\n",
      "Epoch 18/500\n",
      "98/98 [==============================] - 18s 182ms/step - loss: 2.3024 - accuracy: 0.1597 - val_loss: 2.3024 - val_accuracy: 0.1709 - lr: 1.5625e-04\n",
      "Epoch 19/500\n",
      "98/98 [==============================] - 18s 180ms/step - loss: 2.3024 - accuracy: 0.1703 - val_loss: 2.3024 - val_accuracy: 0.1738 - lr: 1.5625e-04\n",
      "Epoch 20/500\n",
      "98/98 [==============================] - 18s 181ms/step - loss: 2.3024 - accuracy: 0.1665 - val_loss: 2.3024 - val_accuracy: 0.1634 - lr: 3.9062e-05\n",
      "Epoch 21/500\n",
      "98/98 [==============================] - 18s 184ms/step - loss: 2.3024 - accuracy: 0.1586 - val_loss: 2.3024 - val_accuracy: 0.1626 - lr: 3.9062e-05\n",
      "Epoch 22/500\n",
      "98/98 [==============================] - 18s 182ms/step - loss: 2.3024 - accuracy: 0.1637 - val_loss: 2.3024 - val_accuracy: 0.1634 - lr: 3.9062e-05\n",
      "Epoch 23/500\n",
      "98/98 [==============================] - 18s 180ms/step - loss: 2.3024 - accuracy: 0.1620 - val_loss: 2.3024 - val_accuracy: 0.1614 - lr: 3.9062e-05\n",
      "Epoch 24/500\n",
      "98/98 [==============================] - 18s 184ms/step - loss: 2.3024 - accuracy: 0.1636 - val_loss: 2.3024 - val_accuracy: 0.1649 - lr: 3.9062e-05\n",
      "Epoch 25/500\n",
      "98/98 [==============================] - 18s 182ms/step - loss: 2.3024 - accuracy: 0.1623 - val_loss: 2.3024 - val_accuracy: 0.1636 - lr: 9.7656e-06\n",
      "Epoch 26/500\n",
      "98/98 [==============================] - 18s 185ms/step - loss: 2.3024 - accuracy: 0.1611 - val_loss: 2.3024 - val_accuracy: 0.1619 - lr: 9.7656e-06\n",
      "Epoch 27/500\n",
      "98/98 [==============================] - 18s 182ms/step - loss: 2.3024 - accuracy: 0.1613 - val_loss: 2.3024 - val_accuracy: 0.1631 - lr: 9.7656e-06\n",
      "Epoch 28/500\n",
      "98/98 [==============================] - 18s 182ms/step - loss: 2.3024 - accuracy: 0.1613 - val_loss: 2.3024 - val_accuracy: 0.1624 - lr: 9.7656e-06\n",
      "Epoch 29/500\n",
      "98/98 [==============================] - 18s 183ms/step - loss: 2.3024 - accuracy: 0.1626 - val_loss: 2.3024 - val_accuracy: 0.1635 - lr: 9.7656e-06\n",
      "Epoch 30/500\n",
      "98/98 [==============================] - 18s 182ms/step - loss: 2.3024 - accuracy: 0.1620 - val_loss: 2.3024 - val_accuracy: 0.1626 - lr: 2.4414e-06\n",
      "Epoch 31/500\n",
      "98/98 [==============================] - 18s 183ms/step - loss: 2.3024 - accuracy: 0.1632 - val_loss: 2.3024 - val_accuracy: 0.1633 - lr: 2.4414e-06\n",
      "Epoch 32/500\n",
      "98/98 [==============================] - 18s 182ms/step - loss: 2.3024 - accuracy: 0.1614 - val_loss: 2.3024 - val_accuracy: 0.1628 - lr: 2.4414e-06\n",
      "Epoch 33/500\n",
      "98/98 [==============================] - 18s 183ms/step - loss: 2.3024 - accuracy: 0.1626 - val_loss: 2.3024 - val_accuracy: 0.1627 - lr: 2.4414e-06\n",
      "Epoch 34/500\n",
      "98/98 [==============================] - 18s 184ms/step - loss: 2.3024 - accuracy: 0.1612 - val_loss: 2.3024 - val_accuracy: 0.1633 - lr: 2.4414e-06\n",
      "Epoch 35/500\n",
      "98/98 [==============================] - 18s 182ms/step - loss: 2.3024 - accuracy: 0.1627 - val_loss: 2.3024 - val_accuracy: 0.1627 - lr: 6.1035e-07\n",
      "Epoch 36/500\n",
      "98/98 [==============================] - 18s 183ms/step - loss: 2.3024 - accuracy: 0.1620 - val_loss: 2.3024 - val_accuracy: 0.1631 - lr: 6.1035e-07\n",
      "Epoch 37/500\n",
      "98/98 [==============================] - 18s 182ms/step - loss: 2.3024 - accuracy: 0.1615 - val_loss: 2.3024 - val_accuracy: 0.1629 - lr: 6.1035e-07\n",
      "Epoch 38/500\n",
      "98/98 [==============================] - 18s 182ms/step - loss: 2.3024 - accuracy: 0.1621 - val_loss: 2.3024 - val_accuracy: 0.1630 - lr: 6.1035e-07\n",
      "Epoch 39/500\n",
      "98/98 [==============================] - 18s 181ms/step - loss: 2.3024 - accuracy: 0.1616 - val_loss: 2.3024 - val_accuracy: 0.1630 - lr: 6.1035e-07\n",
      "Epoch 40/500\n",
      "98/98 [==============================] - 18s 182ms/step - loss: 2.3024 - accuracy: 0.1606 - val_loss: 2.3024 - val_accuracy: 0.1629 - lr: 1.5259e-07\n",
      "Epoch 41/500\n",
      "98/98 [==============================] - 18s 183ms/step - loss: 2.3024 - accuracy: 0.1612 - val_loss: 2.3024 - val_accuracy: 0.1629 - lr: 1.5259e-07\n",
      "Epoch 42/500\n",
      "98/98 [==============================] - 18s 182ms/step - loss: 2.3024 - accuracy: 0.1609 - val_loss: 2.3024 - val_accuracy: 0.1628 - lr: 1.5259e-07\n",
      "Epoch 43/500\n",
      "98/98 [==============================] - 18s 181ms/step - loss: 2.3024 - accuracy: 0.1616 - val_loss: 2.3024 - val_accuracy: 0.1629 - lr: 1.5259e-07\n",
      "Epoch 44/500\n",
      "98/98 [==============================] - 18s 180ms/step - loss: 2.3024 - accuracy: 0.1618 - val_loss: 2.3024 - val_accuracy: 0.1629 - lr: 1.5259e-07\n",
      "Epoch 45/500\n",
      "98/98 [==============================] - 18s 182ms/step - loss: 2.3024 - accuracy: 0.1602 - val_loss: 2.3024 - val_accuracy: 0.1629 - lr: 3.8147e-08\n",
      "Epoch 46/500\n",
      "98/98 [==============================] - 18s 181ms/step - loss: 2.3024 - accuracy: 0.1619 - val_loss: 2.3024 - val_accuracy: 0.1628 - lr: 3.8147e-08\n",
      "Epoch 47/500\n",
      "98/98 [==============================] - 18s 182ms/step - loss: 2.3024 - accuracy: 0.1624 - val_loss: 2.3024 - val_accuracy: 0.1629 - lr: 3.8147e-08\n",
      "Epoch 48/500\n",
      "98/98 [==============================] - 18s 182ms/step - loss: 2.3024 - accuracy: 0.1623 - val_loss: 2.3024 - val_accuracy: 0.1629 - lr: 3.8147e-08\n",
      "Epoch 49/500\n",
      "98/98 [==============================] - 18s 180ms/step - loss: 2.3024 - accuracy: 0.1615 - val_loss: 2.3024 - val_accuracy: 0.1628 - lr: 3.8147e-08\n",
      "Epoch 50/500\n",
      "98/98 [==============================] - 18s 183ms/step - loss: 2.3024 - accuracy: 0.1621 - val_loss: 2.3024 - val_accuracy: 0.1629 - lr: 9.5367e-09\n",
      "Epoch 51/500\n",
      "98/98 [==============================] - 18s 183ms/step - loss: 2.3024 - accuracy: 0.1622 - val_loss: 2.3024 - val_accuracy: 0.1628 - lr: 9.5367e-09\n",
      "Epoch 52/500\n",
      "98/98 [==============================] - 18s 182ms/step - loss: 2.3024 - accuracy: 0.1622 - val_loss: 2.3024 - val_accuracy: 0.1628 - lr: 9.5367e-09\n",
      "Epoch 53/500\n",
      "98/98 [==============================] - 18s 180ms/step - loss: 2.3024 - accuracy: 0.1616 - val_loss: 2.3024 - val_accuracy: 0.1628 - lr: 9.5367e-09\n",
      "Epoch 54/500\n",
      "98/98 [==============================] - 18s 182ms/step - loss: 2.3024 - accuracy: 0.1609 - val_loss: 2.3024 - val_accuracy: 0.1628 - lr: 9.5367e-09\n",
      "Epoch 55/500\n",
      "98/98 [==============================] - 18s 183ms/step - loss: 2.3024 - accuracy: 0.1615 - val_loss: 2.3024 - val_accuracy: 0.1628 - lr: 2.3842e-09\n",
      "Epoch 56/500\n",
      "98/98 [==============================] - 18s 181ms/step - loss: 2.3024 - accuracy: 0.1616 - val_loss: 2.3024 - val_accuracy: 0.1628 - lr: 2.3842e-09\n",
      "Epoch 57/500\n",
      "98/98 [==============================] - 18s 183ms/step - loss: 2.3024 - accuracy: 0.1627 - val_loss: 2.3024 - val_accuracy: 0.1628 - lr: 2.3842e-09\n",
      "Epoch 58/500\n",
      "98/98 [==============================] - 18s 184ms/step - loss: 2.3024 - accuracy: 0.1620 - val_loss: 2.3024 - val_accuracy: 0.1628 - lr: 2.3842e-09\n",
      "Epoch 59/500\n",
      "98/98 [==============================] - 18s 180ms/step - loss: 2.3024 - accuracy: 0.1612 - val_loss: 2.3024 - val_accuracy: 0.1628 - lr: 2.3842e-09\n",
      "Epoch 60/500\n",
      "98/98 [==============================] - 18s 183ms/step - loss: 2.3024 - accuracy: 0.1624 - val_loss: 2.3024 - val_accuracy: 0.1628 - lr: 5.9605e-10\n",
      "Epoch 61/500\n",
      "98/98 [==============================] - 18s 183ms/step - loss: 2.3024 - accuracy: 0.1622 - val_loss: 2.3024 - val_accuracy: 0.1628 - lr: 5.9605e-10\n",
      "Epoch 62/500\n",
      "98/98 [==============================] - 18s 181ms/step - loss: 2.3024 - accuracy: 0.1615 - val_loss: 2.3024 - val_accuracy: 0.1628 - lr: 5.9605e-10\n",
      "Epoch 63/500\n",
      "98/98 [==============================] - 18s 182ms/step - loss: 2.3024 - accuracy: 0.1629 - val_loss: 2.3024 - val_accuracy: 0.1628 - lr: 5.9605e-10\n",
      "Epoch 64/500\n",
      "98/98 [==============================] - 18s 183ms/step - loss: 2.3024 - accuracy: 0.1619 - val_loss: 2.3024 - val_accuracy: 0.1628 - lr: 5.9605e-10\n",
      "Epoch 65/500\n",
      "98/98 [==============================] - 18s 182ms/step - loss: 2.3024 - accuracy: 0.1621 - val_loss: 2.3024 - val_accuracy: 0.1628 - lr: 1.4901e-10\n",
      "Epoch 66/500\n",
      "98/98 [==============================] - 18s 182ms/step - loss: 2.3024 - accuracy: 0.1622 - val_loss: 2.3024 - val_accuracy: 0.1628 - lr: 1.4901e-10\n",
      "Epoch 67/500\n",
      "98/98 [==============================] - 18s 182ms/step - loss: 2.3024 - accuracy: 0.1618 - val_loss: 2.3024 - val_accuracy: 0.1628 - lr: 1.4901e-10\n",
      "Epoch 68/500\n",
      "98/98 [==============================] - 18s 185ms/step - loss: 2.3024 - accuracy: 0.1616 - val_loss: 2.3024 - val_accuracy: 0.1628 - lr: 1.4901e-10\n",
      "Epoch 69/500\n",
      "98/98 [==============================] - 18s 183ms/step - loss: 2.3024 - accuracy: 0.1615 - val_loss: 2.3024 - val_accuracy: 0.1628 - lr: 1.4901e-10\n",
      "Epoch 70/500\n",
      "98/98 [==============================] - 18s 182ms/step - loss: 2.3024 - accuracy: 0.1614 - val_loss: 2.3024 - val_accuracy: 0.1628 - lr: 3.7253e-11\n",
      "Epoch 71/500\n",
      "98/98 [==============================] - 18s 184ms/step - loss: 2.3024 - accuracy: 0.1619 - val_loss: 2.3024 - val_accuracy: 0.1628 - lr: 3.7253e-11\n",
      "Epoch 72/500\n",
      "98/98 [==============================] - 18s 183ms/step - loss: 2.3024 - accuracy: 0.1616 - val_loss: 2.3024 - val_accuracy: 0.1628 - lr: 3.7253e-11\n",
      "Epoch 73/500\n",
      "98/98 [==============================] - 18s 183ms/step - loss: 2.3024 - accuracy: 0.1604 - val_loss: 2.3024 - val_accuracy: 0.1628 - lr: 3.7253e-11\n",
      "Epoch 74/500\n",
      "98/98 [==============================] - 18s 183ms/step - loss: 2.3024 - accuracy: 0.1625 - val_loss: 2.3024 - val_accuracy: 0.1628 - lr: 3.7253e-11\n",
      "Epoch 75/500\n",
      "98/98 [==============================] - 18s 185ms/step - loss: 2.3024 - accuracy: 0.1619 - val_loss: 2.3024 - val_accuracy: 0.1628 - lr: 9.3132e-12\n",
      "Epoch 76/500\n",
      "98/98 [==============================] - 20s 204ms/step - loss: 2.3024 - accuracy: 0.1622 - val_loss: 2.3024 - val_accuracy: 0.1628 - lr: 9.3132e-12\n",
      "Epoch 77/500\n",
      "98/98 [==============================] - 20s 209ms/step - loss: 2.3024 - accuracy: 0.1611 - val_loss: 2.3024 - val_accuracy: 0.1628 - lr: 9.3132e-12\n",
      "Epoch 78/500\n",
      "98/98 [==============================] - 21s 210ms/step - loss: 2.3024 - accuracy: 0.1624 - val_loss: 2.3024 - val_accuracy: 0.1628 - lr: 9.3132e-12\n",
      "Epoch 79/500\n",
      "98/98 [==============================] - 20s 207ms/step - loss: 2.3024 - accuracy: 0.1605 - val_loss: 2.3024 - val_accuracy: 0.1628 - lr: 9.3132e-12\n",
      "Epoch 80/500\n",
      "98/98 [==============================] - 20s 207ms/step - loss: 2.3024 - accuracy: 0.1614 - val_loss: 2.3024 - val_accuracy: 0.1628 - lr: 2.3283e-12\n",
      "Epoch 81/500\n",
      "98/98 [==============================] - 20s 207ms/step - loss: 2.3024 - accuracy: 0.1611 - val_loss: 2.3024 - val_accuracy: 0.1628 - lr: 2.3283e-12\n",
      "Epoch 82/500\n",
      "98/98 [==============================] - 20s 207ms/step - loss: 2.3024 - accuracy: 0.1617 - val_loss: 2.3024 - val_accuracy: 0.1628 - lr: 2.3283e-12\n",
      "Epoch 83/500\n",
      "98/98 [==============================] - 21s 210ms/step - loss: 2.3024 - accuracy: 0.1621 - val_loss: 2.3024 - val_accuracy: 0.1628 - lr: 2.3283e-12\n",
      "Epoch 84/500\n",
      "98/98 [==============================] - 23s 229ms/step - loss: 2.3024 - accuracy: 0.1622 - val_loss: 2.3024 - val_accuracy: 0.1628 - lr: 2.3283e-12\n",
      "Epoch 85/500\n",
      "98/98 [==============================] - 22s 227ms/step - loss: 2.3024 - accuracy: 0.1620 - val_loss: 2.3024 - val_accuracy: 0.1628 - lr: 5.8208e-13\n",
      "Epoch 86/500\n",
      "98/98 [==============================] - 22s 228ms/step - loss: 2.3024 - accuracy: 0.1619 - val_loss: 2.3024 - val_accuracy: 0.1628 - lr: 5.8208e-13\n",
      "Epoch 87/500\n",
      "98/98 [==============================] - 23s 231ms/step - loss: 2.3024 - accuracy: 0.1614 - val_loss: 2.3024 - val_accuracy: 0.1628 - lr: 5.8208e-13\n",
      "Epoch 88/500\n",
      "98/98 [==============================] - 22s 228ms/step - loss: 2.3024 - accuracy: 0.1619 - val_loss: 2.3024 - val_accuracy: 0.1628 - lr: 5.8208e-13\n",
      "Epoch 89/500\n",
      "98/98 [==============================] - 23s 229ms/step - loss: 2.3024 - accuracy: 0.1615 - val_loss: 2.3024 - val_accuracy: 0.1628 - lr: 5.8208e-13\n",
      "Epoch 90/500\n",
      "98/98 [==============================] - 22s 229ms/step - loss: 2.3024 - accuracy: 0.1614 - val_loss: 2.3024 - val_accuracy: 0.1628 - lr: 1.4552e-13\n",
      "Epoch 91/500\n",
      "98/98 [==============================] - 23s 230ms/step - loss: 2.3024 - accuracy: 0.1611 - val_loss: 2.3024 - val_accuracy: 0.1628 - lr: 1.4552e-13\n",
      "Epoch 92/500\n",
      "31/98 [========>.....................] - ETA: 14s - loss: 2.3024 - accuracy: 0.1623"
     ]
    }
   ],
   "source": [
    "H = vgg19_model.fit(aug.flow(x_train, y_train, batch_size=batch_size),\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        epochs=epochs,\n",
    "                        # steps_per_epoch=len(x_train) // batch_size,\n",
    "                        verbose=1)\n",
    "# H = vgg19_model.fit(x_train, y_train,\n",
    "#                         validation_data=(x_test, y_test),\n",
    "#                         epochs=epochs,\n",
    "#                         verbose=1)\n",
    "# Evaluation\n",
    "test_loss, test_accuracy = vgg19_model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
